{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d36b7da",
   "metadata": {},
   "source": [
    "# NER for Extracting Stock Mentions on Reddit\n",
    "\n",
    "## Data Extraction\n",
    "\n",
    "This project is copied and editted from the following project:\n",
    "\n",
    "https://towardsdatascience.com/ner-for-extracting-stock-mentions-on-reddit-aa604e577be"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109cce49",
   "metadata": {},
   "source": [
    "# We build the class to extract data from Reddit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cbf8398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Reddit:\n",
    "    def __init__(self, client_id, secret_token, username, password):\n",
    "        # first create authentication object\n",
    "        auth = requests.auth.HTTPBasicAuth(client_id, secret_token)\n",
    "        # build login dictionary\n",
    "        login = {'grant_type': 'password',\n",
    "                 'username': username,\n",
    "                 'password': password}\n",
    "        # setup header info (incl description of API)\n",
    "        headers = {'User-Agent': 'MyBot/0.0.1'}\n",
    "        # send request for OAuth token\n",
    "        res = requests.post(f'https://www.reddit.com/api/v1/access_token',\n",
    "                            auth=auth, data=login, headers=headers)\n",
    "        # pull auth bearer token from response\n",
    "        token = res.json()['access_token']\n",
    "        # add authorization to headers dictionary\n",
    "        headers['Authorization'] = f'bearer {token}'\n",
    "        # add headers dict to internal attributes\n",
    "        self.headers = headers\n",
    "        # and api\n",
    "        self.api = 'https://oauth.reddit.com'\n",
    "\n",
    "    def get_new(self, subreddit, iters):\n",
    "        # initialize dataframe to store data\n",
    "        df = pd.DataFrame()\n",
    "        # initialize parameters dictionary\n",
    "        params = {'limit': 100}\n",
    "        # iterate through several times to make sure we get all the data available\n",
    "        for i in tqdm(range(iters)):\n",
    "            #print(i+1, 'iteration')\n",
    "            # make request\n",
    "            res = requests.get(f'{self.api}/r/{subreddit}/new',\n",
    "                               headers=self.headers,\n",
    "                               params=params)\n",
    "            # check that we returned something (if not we reached end)\n",
    "            if len(res.json()['data']['children']) == 0:\n",
    "                print('No more found')\n",
    "                return df\n",
    "            # iterate through each thread recieved\n",
    "            for thread in res.json()['data']['children']:\n",
    "                # add info to dataframe\n",
    "                df = df.append({\n",
    "                    'id': thread['data']['name'],\n",
    "                    'created_utc': int(thread['data']['created_utc']),\n",
    "                    'subreddit': thread['data']['subreddit'],\n",
    "                    'title': thread['data']['title'],\n",
    "                    'selftext': thread['data']['selftext'],\n",
    "                    'upvote_ratio': thread['data']['upvote_ratio'],\n",
    "                    'ups': thread['data']['ups'],\n",
    "                    'downs': thread['data']['downs'],\n",
    "                    'score': thread['data']['score']\n",
    "                }, ignore_index=True)\n",
    "            # get earliest ID\n",
    "            earliest = df['id'].iloc[len(df)-1]\n",
    "            # add earliest ID to params\n",
    "            params['after'] = earliest\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b801130b",
   "metadata": {},
   "source": [
    "# Create Reddit Account to use the API\n",
    "\n",
    "Follow this link to learn how to use the reddit API\n",
    "\n",
    "https://towardsdatascience.com/how-to-use-the-reddit-api-in-python-5e05ddfd1e5c\n",
    "\n",
    "Save the username and password to \"code.txt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5587fd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"code.txt\", \"r\")\n",
    "lines = f.readlines()\n",
    "\n",
    "CLIENT_ID = 'mxE3AUoy4bVKv6sQVE1UPg'\n",
    "SECRET_TOKEN = 'QdF0DSYTBAEQjIHvghjOWhp41IE16Q'\n",
    "USER = lines[0].replace('\\n','')\n",
    "PWD = lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b5ba0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = Reddit(CLIENT_ID, SECRET_TOKEN, USER, PWD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e9b12b",
   "metadata": {},
   "source": [
    "# List stock/investing related subreddit for NER extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cde7b3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_list = [\n",
    "            'investing',\n",
    "            'wallstreetbets',\n",
    "            'stocks',\n",
    "            'pennystocks',\n",
    "            'robinhood',\n",
    "            'GME',\n",
    "            'amcstock',\n",
    "            'Cryptocurrency',\n",
    "            'smallstreetbets',\n",
    "            'traders',\n",
    "            'Wallstreetbetsnew',\n",
    "            'options',\n",
    "            'StockMarket',\n",
    "            'ethtrader',\n",
    "           ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a07aa7",
   "metadata": {},
   "source": [
    "# Loop through subreddit and save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a26ce712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "investing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [01:00<01:00,  6.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more found\n",
      "\n",
      "wallstreetbets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [01:38<01:38,  9.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more found\n",
      "\n",
      "stocks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [01:20<01:20,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pennystocks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:52<01:04,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "robinhood\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:22<01:29,  5.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more found\n",
      "\n",
      "GME\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:59<00:59,  5.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more found\n",
      "\n",
      "amcstock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [01:15<01:15,  7.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more found\n",
      "\n",
      "Cryptocurrency\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [01:34<01:34,  9.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more found\n",
      "\n",
      "smallstreetbets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [01:12<01:12,  7.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more found\n",
      "\n",
      "traders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:30<00:45,  3.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more found\n",
      "\n",
      "Wallstreetbetsnew\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [01:03<01:17,  7.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more found\n",
      "\n",
      "options\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:59<01:13,  6.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more found\n",
      "\n",
      "StockMarket\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [02:02<02:30, 13.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more found\n",
      "\n",
      "ethtrader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [01:02<01:15,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for SUB in SUB_list:\n",
    "    print('\\n' + SUB)\n",
    "    data = reddit.get_new(SUB, 20)\n",
    "    data = data.replace({'|': ''}, regex=True)\n",
    "    data.to_csv(f'./data/reddit_{SUB}_NEW.csv', sep='|', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd264f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd219014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
